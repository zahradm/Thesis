{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zahradm/Thesis/blob/main/AdversarialTraining.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H7FojUQM4cqD"
      },
      "outputs": [],
      "source": [
        "!pip install transformers textattack sentence_transformers torchfile evaluate "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "BGNRPr5L5lNf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers\n",
        "import textattack\n",
        "import pandas as pd\n",
        "from datasets import load_dataset, Dataset\n",
        "from transformers import AutoModel\n",
        "from transformers import pipeline, AutoModelForTokenClassification, AutoModelForSequenceClassification\n",
        "from transformers import AutoTokenizer\n",
        "from textattack.augmentation.recipes import  *\n",
        "import numpy as np\n",
        "import evaluate\n",
        "from transformers import TrainingArguments, Trainer"
      ],
      "metadata": {
        "id": "TKeLFEcA5mUp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating adversarial data\n"
      ],
      "metadata": {
        "id": "2RaKTgmu5RjI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = transformers.AutoModelForSequenceClassification.from_pretrained(\"textattack/roberta-base-rotten-tomatoes\")\n",
        "tokenizer = transformers.AutoTokenizer.from_pretrained(\"textattack/roberta-base-rotten-tomatoes\", truncation=True)\n",
        "model_wrapper = textattack.models.wrappers.HuggingFaceModelWrapper(model, tokenizer)"
      ],
      "metadata": {
        "id": "y-uNRI2rbGEG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset(\"rotten_tomatoes\", split=\"train\")\n",
        "sorted_dataset = dataset.sort('label')\n",
        "shuffled_dataset = sorted_dataset.shuffle(seed=45)\n",
        "shuffled_dataset = textattack.datasets.HuggingFaceDataset(shuffled_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g-1EPLdhbRGZ",
        "outputId": "bef1c1ba-37e1-4eba-fa1e-d4803655bfdc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.builder:Using custom data configuration default\n",
            "WARNING:datasets.builder:Reusing dataset rotten_tomatoes (/root/.cache/huggingface/datasets/rotten_tomatoes/default/1.0.0/40d411e45a6ce3484deed7cc15b82a53dad9a72aafd9f86f8f227134bec5ca46)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attack = textattack.attack_recipes.BAEGarg2019.build(model_wrapper)\n",
        "# Attack 20 samples with CSV logging and checkpoint saved every 5 interval\n",
        "attack_args = textattack.AttackArgs(num_examples=3000, log_to_csv=\"/content/drive/MyDrive/Thesis/log_BAEGarg2019_3.csv\", checkpoint_interval=5, checkpoint_dir=\"checkpoints\", disable_stdout=True)\n",
        "attacker = textattack.Attacker(attack, shuffled_dataset, attack_args)\n",
        "attacker.attack_dataset()"
      ],
      "metadata": {
        "id": "3DvG_juRbZSZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Adversarial data preprocess"
      ],
      "metadata": {
        "id": "TyB3SQUmF9ib"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('/content/drive/MyDrive/Thesis/log_BAEGarg2019_3.csv')\n",
        "\n",
        "def success_sample(data):\n",
        "  selected_example = data.loc[data['result_type']=='Successful']\n",
        "  selected_example.reset_index(inplace=True)\n",
        "  return selected_example\n",
        "\n",
        "def clear_data(data):\n",
        "  data['original_text'] = data['original_text'].astype('str').str.replace(\"[\", \"\", regex=True).astype('str')\n",
        "  data['original_text'] = data['original_text'].astype('str').str.replace(\"]\", \"\", regex=True).astype('str')\n",
        "  data['perturbed_text'] = data['perturbed_text'].astype('str').str.replace(\"[\", \"\", regex=True).astype('str')\n",
        "  data['perturbed_text'] = data['perturbed_text'].astype('str').str.replace(\"]\", \"\", regex=True).astype('str')\n",
        "  return data"
      ],
      "metadata": {
        "id": "FO7F0TXlcxsU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "succsess_adv = success_sample(data)\n",
        "succsess_adv"
      ],
      "metadata": {
        "id": "4nMha760-Dms"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adv_data = clear_data(succsess_adv)\n",
        "adv_data"
      ],
      "metadata": {
        "id": "-rT6xlUX-Wo7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adv_data = adv_data[['perturbed_text', 'ground_truth_output']]\n",
        "adv_data"
      ],
      "metadata": {
        "id": "JxwbDzCt_8dE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adv_data.columns = ['text', 'label']\n",
        "adv_data"
      ],
      "metadata": {
        "id": "GxC89_OmAf99"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Adversarial training and saving model"
      ],
      "metadata": {
        "id": "0Jtj6WpB7WyK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#path = '/content/drive/MyDrive/Thesis/log_BAEGarg2019_3.csv'\n",
        "#adv_data = pd.read_csv(path)\n",
        "#data = data.drop(['Unnamed: 0','index'], axis=1)\n",
        "df = pd.DataFrame(adv_data)\n",
        "rotten_tomatoes = load_dataset(\"rotten_tomatoes\")"
      ],
      "metadata": {
        "id": "s9NorYo17a1L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "ZmGP30eFgeK7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adv_split_index = round(len(df)/10)*8\n",
        "adv_train = df[:adv_split_index]\n",
        "adv_test = df[adv_split_index:]"
      ],
      "metadata": {
        "id": "lQ_ZbY_aZliN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def shuffle(dataName, split):\n",
        "  dataset = load_dataset(dataName, split=split)\n",
        "  sorted_dataset = dataset.sort('label')\n",
        "  shuffled_dataset = sorted_dataset.shuffle(seed=45)\n",
        "  return shuffled_dataset\n"
      ],
      "metadata": {
        "id": "H6YsBo954HHc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shuffle_train = shuffle('rotten_tomatoes','train')\n",
        "shuffle_test = shuffle('rotten_tomatoes', 'validation')\n",
        "benign_train = shuffle_train[:round(len(shuffle_train)/5)]\n",
        "benign_test = shuffle_test[:round(len(shuffle_test)/5)]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0TBXm2RSaMQM",
        "outputId": "8e48410a-80b9-4b26-b2d9-fb038a2d3c74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.builder:Using custom data configuration default\n",
            "WARNING:datasets.builder:Reusing dataset rotten_tomatoes (/root/.cache/huggingface/datasets/rotten_tomatoes/default/1.0.0/40d411e45a6ce3484deed7cc15b82a53dad9a72aafd9f86f8f227134bec5ca46)\n",
            "WARNING:datasets.builder:Using custom data configuration default\n",
            "WARNING:datasets.builder:Reusing dataset rotten_tomatoes (/root/.cache/huggingface/datasets/rotten_tomatoes/default/1.0.0/40d411e45a6ce3484deed7cc15b82a53dad9a72aafd9f86f8f227134bec5ca46)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "benign_train_df = pd.DataFrame(list(zip(benign_train['text'], benign_train['label'])), columns =['text', 'label']) \n",
        "benign_test_df = pd.DataFrame(list(zip(benign_test['text'], benign_test['label'])), columns =['text', 'label']) "
      ],
      "metadata": {
        "id": "XCRI2nMrbxzG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_merged_train = pd.concat([benign_train_df, adv_train], ignore_index=True, sort=False)\n",
        "df_merged_test = pd.concat([benign_test_df, adv_test], ignore_index=True, sort=False)"
      ],
      "metadata": {
        "id": "QThEazdNgPQ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_train = Dataset.from_pandas(df_merged_train)\n",
        "all_test = Dataset.from_pandas(df_merged_test)"
      ],
      "metadata": {
        "id": "2hGOIlwzAO6H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"textattack/roberta-base-rotten-tomatoes\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "def tokenize_function(examples):\n",
        "  return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
        "\n",
        "tokenized_datasets_train = all_train.map(tokenize_function, batched=True)\n",
        "tokenized_datasets_test = all_test.map(tokenize_function, batched=True)"
      ],
      "metadata": {
        "id": "ocKJwMuS-Mm0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
        "\n",
        "training_args = TrainingArguments(output_dir=\"/content/drive/MyDrive/Thesis_roberta_BAG\", evaluation_strategy=\"epoch\", num_train_epochs=8)\n",
        "\n",
        "metric = evaluate.load(\"accuracy\")\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    return metric.compute(predictions=predictions, references=labels)\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_datasets_train,\n",
        "    eval_dataset=tokenized_datasets_test,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "trainer.train()\n",
        "trainer.save_model(\"/content/drive/MyDrive/Thesis_roberta_BAG\")"
      ],
      "metadata": {
        "id": "39meiMbg-SHw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load the model\n",
        "from transformers import AutoModelForSequenceClassification\n",
        "load_model = AutoModelForSequenceClassification.from_pretrained(\"/content/drive/MyDrive/Thesis_roberta_BAG\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"textattack/roberta-base-rotten-tomatoes\")\n"
      ],
      "metadata": {
        "id": "QUf3q6FH-diR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Adversarial attack on trained model"
      ],
      "metadata": {
        "id": "grECjRnf-pbi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_wrapper = textattack.models.wrappers.HuggingFaceModelWrapper(load_model, tokenizer)\n",
        "attack = textattack.attack_recipes.BAEGarg2019.build(model_wrapper)\n",
        "dataset_test = textattack.datasets.HuggingFaceDataset(\"rotten_tomatoes\", split=\"test\")\n",
        "attack_args = textattack.AttackArgs(num_examples=1066, checkpoint_interval=5, checkpoint_dir=\"checkpoints\", disable_stdout=True)\n",
        "attacker = textattack.Attacker(attack, dataset_test, attack_args)\n",
        "attacker.attack_dataset()"
      ],
      "metadata": {
        "id": "jNwnN7Id-sNf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}